{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "251fc41d-e24e-4311-9c79-330038d6faee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2001391-4658-44e4-b982-cc6001674b89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Definition - Autoregressive model**\n",
    "\n",
    "An autoregressive model of order p, written as AR(p), can be written as\n",
    "\n",
    "$$x_t=\\phi_1 x_{t-1} + \\phi_2 x_{t-2} + ... + \\phi_p x_{t-p} + w_t$$\n",
    "\n",
    "Here \\\\(x_t\\\\) is stationary and \\\\(\\phi_p\\\\) are constants and non-zero.\n",
    "\\\\(w_t\\\\) is assumed to be a Gaussian noise series with zero mean and variance \\\\(\\sigma_w^2\\\\).\n",
    "\n",
    "Expanding the AR(1) model recursively we can write\n",
    "\n",
    "$$x_t = \\phi^k x_{t-k} + \\sum_{j=0}^{k-1} \\phi_j w_{t-j}$$\n",
    "\n",
    "Since \\\\(x_t = \\phi_1 x_{t-1} + w_t = \\phi_1 (\\phi_1 x_{t-2} + w_{t-1}) + w_t\\\\) and can be expanded similarly. \n",
    "\n",
    "If \\\\(|\\phi|<1\\\\) the term \\\\(\\phi^k x_{t-k} \\\\) goes to zero. Furthermore, if \\\\(x_t\\\\) is also stationary the AR(1) model can be written as a linear process by\n",
    "\n",
    "$$x_t =  \\sum_{j=0}^{\\infin} \\phi_j w_{t-j}$$\n",
    "\n",
    "This process will have zero mean du to the linearity of the expectation operator.\n",
    "\n",
    "The autocovariance of an AR(1) process is $$\\gamma(h)=\\frac{\\sigma_w^2 \\phi^h}{1 - \\phi^2}$$\n",
    "\n",
    "**Definition - The autoregressive operator**\n",
    "\n",
    "The autoregressive operator is defined as \n",
    "\n",
    "$$\\phi(B)=1 - \\phi_1 B - \\phi_2 B^2 - ... - \\phi_p B^p$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f79298e5-cc47-47b2-b656-2b68c20cbe1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Example - Realization of autoregressive model\n",
    "'''\n",
    "In this example it is seen how the realization of an AR(1) model depends on phi\n",
    "If 0<phi<1 the realization is stationary and the acf show that the linear dependence between samples are steadily declining\n",
    "If -<phi<0 the realization is stationary and the acf show that the linear dependence between samples are alternating in a decreasing manner\n",
    "If 1<phi the relization is non-stationary\n",
    "'''\n",
    "\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "def ar1_realization(phi):\n",
    "    N = 100\n",
    "    mu, sigma = 0, 1\n",
    "    w = np.random.normal(mu, sigma, N)\n",
    "    x = np.zeros(N)\n",
    "\n",
    "    for i in range(1, N):\n",
    "        x[i] = phi * x[i-1] + w[i]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x)\n",
    "    plt.title(f\"Realization of AR(1) - Phi = {phi}\")\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.ylabel(\"Value\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(acf(x))\n",
    "    plt.title(f\"Autocorrelation of AR(1) - Phi = {phi}\")\n",
    "    plt.xlabel(\"Lag\")\n",
    "    plt.ylabel(\"Value\")\n",
    "\n",
    "ar1_realization(0.9)\n",
    "ar1_realization(-0.9)\n",
    "ar1_realization(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8962df37-99c3-41d8-9f9c-8b6f4ab7e0e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Definition - Moving average model**\n",
    "\n",
    "The moving average model of order q, **MA**(q) is defined as\n",
    "\n",
    "$$ x_t = w_t + \\theta_{1} w_{t-1} + \\theta_{2} w_{t-2} ... + \\theta_{p} w_{t-p}$$\n",
    "\n",
    "Here \\\\(theta\\\\) are the parameters of the model and non-zero. \\\\(w_t\\\\) is Gaussian noise.\n",
    "The moving average process can also be written as\n",
    "\n",
    "$$ x_t = \\theta(B) w_t $$ where \\theta(B) is the mmoving average operator\n",
    "\n",
    "**Definition - The moving average operator**\n",
    "\n",
    "The moving average operator is defined as \n",
    "\n",
    "$$ \\theta(B) = 1 + \\theta_1 B + \\theta_2 B^2 ... \\theta_p B^p $$\n",
    "\n",
    "**Example - MA(1) process**\n",
    "\n",
    "The **MA**(1) process is defined as \n",
    "\n",
    "$$ x_t = w_t + \\theta w_{t-1} $$\n",
    "\n",
    "Here \\\\(E[x_t]=0\\\\) and the autocorrelation is \\\\(\\rho(h)=\\frac{\\theta}{1+\\theta^2}\\\\) when \\\\(h = 1\\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13acd8dd-6b56-4aa4-9d3c-27d3a4b6d624",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Example - Realization of moving average model\n",
    "'''\n",
    "In this example it is seen how the realization of an MA(1) model depends on theta\n",
    "The MA process is always stationary regardless of theta\n",
    "If 0<theta<1 the acf show that the linear dependence between samples are positive at lag 1 and zero after\n",
    "If -<theta<0 the acf show that the linear dependence between samples are negative(Due to the negative theta) at lag 1 and zero after\n",
    "If 1<theta the relization is stationary\n",
    "'''\n",
    "\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "def ma1_realization(phi):\n",
    "    N = 1000\n",
    "    mu, sigma = 0, 1\n",
    "    w = np.random.normal(mu, sigma, N)\n",
    "    x = np.zeros(N)\n",
    "\n",
    "    for i in range(1, N):\n",
    "        x[i] = phi * w[i-1] + w[i]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x)\n",
    "    plt.title(f\"Realization of MA(1) - Phi = {phi}\")\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.ylabel(\"Value\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(acf(x), \"-*\")\n",
    "    plt.title(f\"Autocorrelation of MA(1) - Phi = {phi}\")\n",
    "    plt.xlabel(\"Lag\")\n",
    "    plt.ylabel(\"Value\")\n",
    "\n",
    "ma1_realization(0.9)\n",
    "ma1_realization(-0.9)\n",
    "ma1_realization(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48770f9e-34e9-41ee-aa5b-8c3b02ee0850",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Example - Causality**\n",
    "\n",
    "The moving average process will always be stationary regardless of \\\\(\\theta\\\\) vvalues as shown above. The autoregressive process is however different. COnsider the autoregressive process \n",
    "\n",
    "$$ x_{t} = \\phi x_{t-1} + w_t $$\n",
    "\n",
    "Which can be recursively rewritten to\n",
    "\n",
    "$$ x_{t} = \\phi^p x_{t-p} + \\sum_{j=0}^{p-1} \\phi^j w_{t-j}  $$\n",
    "\n",
    "And if \\\\(| \\phi | < 1\\\\) will converge to \n",
    "\n",
    "$$ x_{t} = \\sum_{j=0}^{p-1} \\phi^j w_{t-j}  $$\n",
    "\n",
    "This shows that an **AR**(1) process can be represented as a linear process with coeffecients \\\\(\\psi_j=\\phi^j\\\\). For a derivation of this, see \"Time Series Analysis and Its Applications\" Shumway & Stoffer page 88.\n",
    "\n",
    "Consider a non-stationary process, the random walk, which is a **AR**(1) process with \\\\(\\phi=1\\\\). Autoregressive processes with \\\\(\\phi>1\\\\) are called explosive and cannot be expressed a linear process. This is because the term \\\\(\\phi^p x_{t-p}\\\\) does not converge to 0.\n",
    "\n",
    "However, the process can be rewritten to another form, to allow representation as a linear process. \n",
    "\n",
    "First a shift forward in time i performed\n",
    "\n",
    "$$ x_{t+1} = \\phi x_{t} + w_{t+1}  $$\n",
    "\n",
    "Then we rewrite to express in terms of \\\\(x_{t}\\\\)\n",
    "\n",
    "$$  x_{t} =  - \\phi^{-1} w_{t+1} + \\phi^{-1} x_{t+1}  $$\n",
    "\n",
    "Now, recursively substituting \\\\(x_{t+1}\\\\) yields\n",
    "\n",
    "$$ x_{t} = \\phi^{-p} x_{t+p} - \\sum_{j=1}^{p} \\phi^{-j} w_{t+j}  $$\n",
    "\n",
    "It is seen that for \\\\(\\theta> 1\\\\) the term \\\\(\\phi^{-p} x_{t+p}\\\\) converges to 0 and we are back at expressing \\\\(x_t\\\\) as a linear process. But instead of describing \\\\(x_t\\\\) as a linear process of past errors it is expressed in terms of future. This is then a non-causal system.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2feb09fc-f63f-475a-a162-62df8aec1a7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Definition AR and MA polynomials**\n",
    "\n",
    "The ARMA process can be written as\n",
    "\n",
    "$$ \\phi(B) x_t = \\theta(B) w_t $$\n",
    "\n",
    "Where \\\\(\\phi(B)\\\\) and \\\\(\\theta(B)\\\\) are the characteristic equations.\n",
    "\n",
    "The AR and MA polynomials are defined as \n",
    "\n",
    "$$ \\phi(z) = 1 - \\phi_1 z - \\phi_2 z^2 - ... - \\phi_p z^p $$\n",
    "\n",
    "$$ \\theta(z) = 1 + \\theta_1 z + \\theta_2 z^2 + ... + \\theta_p z^p $$\n",
    "\n",
    "Where in the characteristic equation we switch B with z which is a complex number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aedb3970-a32d-44cf-9f3f-63cfbf74b2b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Definition - Causality**\n",
    "\n",
    "For an **ARMA**(p,q) process to be causal, it needs to be representable as a linear process of past errors.\n",
    "\n",
    "$$ x_{t} = \\sum_{j=0}^{\\infin} \\psi_{j} w_{t-j} = \\psi(B) w_t $$\n",
    "\n",
    "Since \\\\( \\phi(B) x_t = \\theta(B) w_t \\\\) and conversely \\\\(x_t = \\frac{\\theta(B)}{\\phi(B)} w_t\\\\) we can rewrite this to\n",
    "\n",
    "$$ \\frac{\\theta(B)}{\\phi(B)} w_t = \\sum_{j=0}^{\\infin} \\psi_{j} w_{t-j} = \\psi(B) w_t $$\n",
    "\n",
    "Setting \\\\(w_{t-j}\\\\) to \\\\(w_t B^j\\\\) and cancelling \\\\(w_t\\\\) in all terms\n",
    "\n",
    "$$ \\frac{\\theta(B)}{\\phi(B)} = \\sum_{j=0}^{\\infin} \\psi_{j} B^j = \\psi(B) $$\n",
    "\n",
    "Substituting \\\\(B\\\\) by \\\\(z\\\\) \n",
    "\n",
    "$$ \\frac{\\theta(z)}{\\phi(z)} = \\sum_{j=0}^{\\infin} \\psi_{j} z^j = \\psi(z) $$\n",
    "\n",
    "In order to make sure that the system is causal, meaning that we can write is as a linear process og past errors, all AR parameters needs to have magnitude less than 1. For this to be true, all roots of the characteristic eqation has to lie outside the unit circle.\n",
    "\n",
    "**Example - Causal AR(1) process**\n",
    "\n",
    "Consider the causal **AR**(1) process \n",
    "\n",
    "$$ x_t = 0.3x_t + w_t $$\n",
    "\n",
    "We know it is causal, since \\\\(abs(\\phi) < 1\\\\)\n",
    "\n",
    "Here \\\\(\\phi(B)=1-0.3B\\\\) hence \\\\(\\phi(z)=1-0.3z\\\\). The characteristic equation has the root \\\\(z=\\frac{1}{0.3}\\\\) which is outside the unit circle. \n",
    "\n",
    "**Example - Non-causal AR(1) process**\n",
    "\n",
    "Let's go the other way and define a characteristic equation\n",
    "\n",
    "$$ \\phi(z) = (1-2z) $$ This has the root \\\\(z=\\frac{1}{2}\\\\). Writing out the **AR**(1) process that generates this characteristic equation\n",
    "\n",
    "$$ x_t(1-2B)=w_t $$\n",
    "\n",
    "$$ x_t = 2x_{t-1} + w_t $$\n",
    "\n",
    "Here we see that \\\\(\\phi=2\\\\) which cannot be expressed as a linear combinarion of past errors as shown before.\n",
    "\n",
    "**Example - Non-causal AR(2) process**\n",
    "\n",
    "Defining a characteristic equation with one root inside and one root outside of the unit circle\n",
    "\n",
    "$$ \\phi(z)=(1-0.1z)(1+2z)=1+2z-0.1z-0.2z^2$$\n",
    "\n",
    "This will result in thr AR process\n",
    "\n",
    "$$ x_t(1+1.9B-0.2B^2) = w_t $$\n",
    "\n",
    "Rewriting to\n",
    "\n",
    "$$ x_t = - 1.9 x_t + 0.2 x_{t-2} + w_t $$\n",
    "\n",
    "Here we see that we have \\\\(abs(\\phi_1)>1\\\\) which will yield a non-causal system\n",
    "\n",
    "**Intuition - Causality**\n",
    "\n",
    "The reason we care if an AR process is causal, is that we want the current obersavation \\\\(x_t\\\\) to depend only on past values. This means we can forecast new values, since the future values will only depend on past values(\\\\(x_{t+1}\\\\) will only depend on available values).\n",
    "In signal processing, to perform real-time filtering we need to only depend on previous and current samples, hence a causal system is nescassary.\n",
    "Similarly in control theory, we want our system output to only depend on past and present inputs and not future inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e31efc3-f004-4aee-9ce6-3ec62c1fe7f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Example - Invertibility**\n",
    "\n",
    "Consider the **MA**(1) process\n",
    "\n",
    "$$ x_t = \\theta w_{t-1} + w_t $$\n",
    "\n",
    "Here the current value depend on the previous error \\\\(w_{t-1}\\\\) and the current error \\\\(w_{t}\\\\). Since we only have observations readily available, and not the error, we want to model this in terms of past observations \\\\(x_{t-n}\\\\) instead.\n",
    "\n",
    "This leads to the notion of an **AR**(\\\\(\\infin\\\\)) process \n",
    "\n",
    "Rewriting the process to\n",
    "\n",
    "$$ x_t = \\theta w_{t-1} + w_t = (1+\\theta B) w_t $$\n",
    "\n",
    "$$ \\frac{x_t}{1+\\theta B} = w_t $$\n",
    "\n",
    "We recognize that \\\\(\\frac{1}{1+\\theta B}\\\\) can be expressed as an infinite geometric series with the common factor 1.\n",
    "\n",
    "$$ \\frac{1}{1+\\theta B} = \\sum_{j=0}^\\infin (-\\theta) B^j$$\n",
    "\n",
    "$$ x_t \\sum_{j=0}^\\infin (-\\theta)^j B^j = w_t $$\n",
    "\n",
    "Which if written out will become\n",
    "\n",
    "$$ x_t (1 + (-\\theta) B + (-\\theta)^2 B^2 - ...) = w_t $$\n",
    "\n",
    "Which we recognize as an infinite AR process **AR**(\\\\(\\infin\\\\)).\n",
    "\n",
    "This is much more useful than the actual **MA**(1) process here we only depend on the previous observations and the current error.\n",
    "\n",
    "**Definition - Invertibility**\n",
    "\n",
    "A time series is said to be invertible if it can be written as \n",
    "\n",
    "$$ \\pi(B )x_{t} = \\sum_{j=0}^{\\infin} \\pi_{j} x_{t-j} = w_t $$\n",
    "\n",
    "Meaning that hte current observation is a linear combination of all previous combinarion and the current error.\n",
    "\n",
    "This is invertible if \\\\(\\theta(z)\\\\) has all the roots outside of the unit circle.\n",
    "\n",
    "**Example - Invertible MA(1) process**\n",
    "\n",
    "Consider the **MA**(1) process \n",
    "\n",
    "$$ x_t = 0.4 w_{t-1} + w_t $$\n",
    "\n",
    "This can be rewritten to the **AR**(1) process \n",
    "\n",
    "$$ x_t \\sum_{j=0}^\\infin (-0.4)^j B^j = w_t $$\n",
    "\n",
    "$$ x_t = -0.4 x_t - 0.4^2 x_{t-2} ... + w_t $$\n",
    "\n",
    "Which is stationary and causal since \\\\(abs(\\phi) < 1\\\\). The original MA process will have the MA polynomial\n",
    "\n",
    "$$ \\theta(z) = (1+0.4z) $$\n",
    "\n",
    "With the root \\\\(z=\\frac{1}{0.4}\\\\) which lies outside of the unit circle.\n",
    "\n",
    "**Example - Non-invertible MA(1) process**\n",
    "\n",
    "$$ x_t = 2 w_{t-1} + w_t $$\n",
    "\n",
    "This can be rewritten to the **AR**(1) process \n",
    "\n",
    "$$ x_t \\sum_{j=0}^\\infin (-2)^j B^j = w_t $$\n",
    "\n",
    "$$ x_t = -2 x_t - 2^2 x_{t-2} ... + w_t $$\n",
    "\n",
    "Which is non-stationary and non-causal since \\\\(abs(\\phi) > 1\\\\). The original MA process will have the MA polynomial\n",
    "\n",
    "$$ \\theta(z) = (1+2z) $$\n",
    "\n",
    "With the root \\\\(z=\\frac{1}{2}\\\\) which lies inside of the unit circle.\n",
    "\n",
    "**Intuition - Invertibility**\n",
    "\n",
    "We want to be able to express our time series as a linear combination of current and past observations. If \\\\(abs(\\theta) < 1\\\\) the current observations \\\\(x_t\\\\) will depend more on recent observations that on past observations. If \\\\(abs(\\theta) = 1\\\\) the past observations will have same weight as the current observations.\n",
    "In many systems(but not all) the two latter is not desireable properties, hence we favour invertible systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "648ebdb4-b9f0-421a-ba4d-d7bf7f79acf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Definition - Parameter redundancy**\n",
    "\n",
    "An ARMA model has no redundant parameters if it does not have duplicate roots in the AR or MA polynomials \\\\(\\phi(z)\\\\) or \\\\(\\theta(z)\\\\)."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Autoregressive models",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
